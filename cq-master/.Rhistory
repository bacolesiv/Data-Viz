edu #data from the socviz package #messy because years of schooling is split into like 5 varaibles
#Using gather() and spread() to consolidate the data
edu_t <- edu %>%
gather(key = years.school, #creates new column years.school and puts the variables you want to gather in the cells
value = freq, #will give counts for each category
elem4:coll4) # what variables you want to gather
dim(edu_t) #2196 rows X 7 columns = long data
dim(edu) #366 rows X 11 columns = compact data for display
gapminder #just data doesnt come with functions? #library(readxl) provides functions for reading excel data
edu #data from the socviz package #messy because years of schooling is split into like 5 varaibles
#Using gather() and spread() to consolidate the data
edu_t <- edu %>%
gather(key = years.school, #creates new column years.school and puts the variables you want to gather in the cells
value = freq, #will give counts for each category
elem4:coll4) # what variables you want to gather
dim(edu_t) #2196 rows X 7 columns = long data
dim(edu) #366 rows X 11 columns = compact data for display
#Conceptually its just merging tables
#*left*_join() preserves values from the *left* table - things from the right with no matching columns will get NA's
#inner_join analogus to the intersection of the data so the only thing preserved is what they share not whats on the left or right
#full_join keeps everything from both - union that preserves everything
#anti_join & semi_join filtering joins
#Question 6 from Slack problems requires a join
senate <- data %>%
filter(position == "U.S. Senator") %>%
group_by(pid) %>% #the variable that uniquely identifies the congress people
summarise(first = first(first),
last = first(last),
party = first(party),
state = first(state),
start = first(start),
end = first(end))
house <- data %>%
filter(position == "U.S. Representative") %>%
group_by(pid) %>% #matching variable
summarise(first = first(first),
last = first(last),
start = first(start),
end = first(end))
sen.house <- inner_join(senate, house, by = "pid") #matching variable used in by arguement here #anti_join would exclude people who have served in both the house and the senate
#stringr - str_detect(string, patter) - str_replace(string, pattern, replacement) these functions are pipeable
#string = variable - pattern = value - replacement = replace value
#str_remove(variable, "value to delete") - useful for handling missing data? " NA$" kieran said use this in the "value to delete"
#There is a link to exercises with regular expression on slack socviz
#mac book patterns app -> test bed for regular expressions -> shows you what youre finding/replacing
install.packages("naniar")
install.packages("visdat")
library(naniar)
library(visdat)
vis_dat(sen.house)
vis_dat(data)
data(tulips)
data <- tulips
library(tidyverse)
library(rethinking)
data(tulips)
data <- tulips
summary(data)
data$bed.cats <- coerce_index(data$bed)
data$shade.cent <- data$shade - mean(data$shade)
data$water.cent <- data$water - mean(data$water)
m1 <- map(alist(
blooms ~ dnorm(mu, sigma),
mu <- a + b1*water.cent + b2*shade.cent + b3*water.cent*shade.cent,
a ~ dnorm(128, 92),
b1 ~ dnorm(0, 80),
b2 ~ dnorm(0, 80),
b3 ~ dnorm(0, 80),
sigma ~ dunif(0, 100)), data = data, method="Nelder-Mead", control=list(maxit=1e4))
m2 <- map(alist(
blooms ~ dnorm (mu, sigma),
mu <- a + b1*bed.cats + b2*water.cent + b3*shade.cent + b4*water.cent*shade.cent,
a ~ dnorm(128, 92),
b1 ~ dnorm(0, 80),
b2 ~ dnorm(0, 80),
b3 ~ dnorm(0, 80),
b4 ~ dnorm(0, 80),
sigma ~ dunif(0, 100)), data = data, method="Nelder-Mead", control=list(maxit=1e4))
compare(m1, m2)
precis(m2)
posterior.samples <- extract.samples(m2)
posterior.samples %>%
ggplot(aes(x = b1)) +
geom_histogram(binwidth = 1) + labs(x = "Bed Index Betas", title = "Posterior Distribution of Bed Index Coefficients")
sessionInfo()
library(socviz)
library(tidyverse)
data(organdata)
organdata %>%
group_by(world) %>%
summarize_if(is.numeric, mean, na.rm = T) %>%
organdata %>%
group_by(world) %>%
summarize_if(is.numeric, mean, na.rm = T)
a <- organdata %>%
group_by(world) %>%
summarize_if(is.numeric, mean, na.rm = T) %>%
a
organdata <- data(organdata)
organdata %>%
group_by(world) %>%
summarize_if(is.numeric, mean, na.rm = T)
out <- lm(donors ~ pop + gdp + roads, data = organdata)
library(socviz)
library(tidyverse)
organdata <- data(organdata)
data(organdata)
data(organdata)
library(socviz)
library(tidyverse)
data("organdata")
organdata %>%
group_by(world) %>%
summarize_if(is.numeric, mean, na.rm = T) %>%
select(world, donors, pubhealth, roads) %>%
select_all(tools::toTitleCase)
organdata %>%
group_by(country) %>%
summarize_if(is.numeric, funs(ave = mean, sd = sd), na.rm = T) %>% #funs(is similar to mutate but for creating colomns for means sds, etc)
select(country, donors_avg, donors_sd, roads_avg, roads_sd) %>%
arrange(desc(donors_avg))
organdata %>%
group_by(country) %>%
summarize_if(is.numeric, funs(ave = mean, sd = sd), na.rm = T) %>% #funs(is similar to mutate but for creating colomns for means sds, etc)
select(country, donors_avg, donors_sd, roads_avg, roads_sd) %>%
arrange(desc(donors_avg))
out <- lm(donors ~ pop + gdp + roads, data = organdata)
organdata %>%
split(.$world) %>%
map(~lm(donors ~ pop + gdp + roads, data = .)) %>%
map(summary) %>%
map_dbl("r.squared")
organdata %>%
split(.$world) %>% #used split so thqt we didnt have to enclose all the maps in a mutate function
map(~lm(donors ~ pop + gdp + roads, data = .)) %>%
map(summary) %>%
map_dbl("r.squared")
remove.packages("rethinking")
organdata %>%
split(.$world) %>% #used split so thqt we didnt have to enclose all the maps in a mutate function
map(~lm(donors ~ pop + gdp + roads, data = .)) %>%
map(summary) %>%
map_dbl("r.squared")
library(purrr)
organdata %>%
split(.$world) %>% #used split so thqt we didnt have to enclose all the maps in a mutate function
map(~lm(donors ~ pop + gdp + roads, data = .)) %>%
map(summary) %>%
map_dbl("r.squared")
install.packages("rethinking")
install.packages("rethinking")
data(nettle)
data <- nettle
library(tidyverse)
library(rethinking)
data(nettle)
data <- nettle
data(nettle)
data <- nettle
data("nettle")
data <- nettle
library(rethinking)
install.packages("rethinking")
install.packages(c("mvtnorm","loo","coda"), repos="https://cloud.r-project.org/",dependencies=TRUE)
options(repos=c(getOption('repos'), rethinking='http://xcelab.net/R'))
install.packages('rethinking',type='source')
library(rethinking)
data("nettle")
data <- nettle
data <- data %>%
mutate(lang.per.cap = num.lang / k.pop,
log.area = log(area),
log.lang.per.cap = log(lang.per.cap),
sgs.center = sd.growing.season - mean(sd.growing.season),
log.area.center = log.area - mean(log.area),
mgs.center = mean.growing.season - mean(mean.growing.season))
data <- as.data.frame(data)
model.a1 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*mean.growing.season + b2*log.area,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
model.a2 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*mgs.center + b2*log.area,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
compare(model.a1, model.a2)
precis(model.a2, digits = 3) #model.a2
predictions <-
as.tibble(MASS::mvrnorm(mu = model.a2@coef, Sigma = model.a2@vcov , n = 1e4)) %>% #rather than extract.samples
mutate(mean.growing.season = sample(data$mean.growing.season, 1e4, replace = T),
log.area = sample(data$log.area, 1e4, replace = T),
pred.mu = a + b1*mean.growing.season + b2*log.area, #line uncertainty
pred.lang= rnorm(1e4, pred.mu, sigma )) %>%         #data uncertainty
group_by(log.area) %>%
mutate(lb.mu = rethinking::HPDI(pred.mu, prob = .89)[1],
ub.mu = rethinking::HPDI(pred.mu, prob = .89)[2],
lb.lang = rethinking::HPDI(pred.lang, prob = .89)[1],
ub.lang = rethinking::HPDI(pred.lang, prob = .89)[2]) %>%
slice(1) %>%
mutate(lang.hat = model.a2@coef["a"] + model.a2@coef["b1"]*mean.growing.season + model.a2@coef["b2"]*log.area) %>% # yhat for reg line
select(lang.hat, log.area, lb.mu, ub.mu, lb.lang, ub.lang)
a <- data %>%
ggplot(aes(mean.growing.season)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Meaning Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
library(rethinking)
data("nettle")
data <- nettle
data <- data %>%
mutate(lang.per.cap = num.lang / k.pop,
log.area = log(area),
log.lang.per.cap = log(lang.per.cap),
sgs.center = sd.growing.season - mean(sd.growing.season),
log.area.center = log.area - mean(log.area),
mgs.center = mean.growing.season - mean(mean.growing.season))
model.a1 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*mean.growing.season + b2*log.area,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
model.a2 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*mgs.center + b2*log.area,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
compare(model.a1, model.a2)
precis(model.a2, digits = 3) #model.a2
predictions <-
as.tibble(MASS::mvrnorm(mu = model.a2@coef, Sigma = model.a2@vcov , n = 1e4)) %>% #rather than extract.samples
mutate(mean.growing.season = sample(data$mean.growing.season, 1e4, replace = T),
log.area = sample(data$log.area, 1e4, replace = T),
pred.mu = a + b1*mean.growing.season + b2*log.area, #line uncertainty
pred.lang= rnorm(1e4, pred.mu, sigma )) %>%         #data uncertainty
group_by(log.area) %>%
mutate(lb.mu = rethinking::HPDI(pred.mu, prob = .89)[1],
ub.mu = rethinking::HPDI(pred.mu, prob = .89)[2],
lb.lang = rethinking::HPDI(pred.lang, prob = .89)[1],
ub.lang = rethinking::HPDI(pred.lang, prob = .89)[2]) %>%
slice(1) %>%
mutate(lang.hat = model.a2@coef["a"] + model.a2@coef["b1"]*mean.growing.season + model.a2@coef["b2"]*log.area) %>% # yhat for reg line
select(lang.hat, log.area, lb.mu, ub.mu, lb.lang, ub.lang)
a <- data %>%
ggplot(aes(mean.growing.season)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Meaning Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
a <- data %>%
ggplot(aes(mean.growing.season)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a
a <- data %>%
ggplot(aes(x = data$mean.growing.season)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Meaning Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
a <- data %>% ggplot(aes(mean.growing.season)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Meaning Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
a <- data %>%
ggplot(aes(data$mean.growing.season)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Meaning Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
predictions <-
as.tibble(MASS::mvrnorm(mu = model.a2@coef, Sigma = model.a2@vcov , n = 1e4)) %>% #rather than extract.samples
mutate(mean.growing.season = sample(data$mean.growing.season, 1e4, replace = T),
log.area = sample(data$log.area, 1e4, replace = T),
pred.mu = a + b1*mean.growing.season + b2*log.area, #line uncertainty
pred.lang= rnorm(1e4, pred.mu, sigma )) %>%         #data uncertainty
group_by(log.area) %>%
mutate(lb.mu = rethinking::HPDI(pred.mu, prob = .97)[1],
ub.mu = rethinking::HPDI(pred.mu, prob = .97)[2],
lb.lang = rethinking::HPDI(pred.lang, prob = .97)[1],
ub.lang = rethinking::HPDI(pred.lang, prob = .97)[2]) %>%
slice(1) %>%
mutate(lang.hat = model.a2@coef["a"] + model.a2@coef["b1"]*mean.growing.season + model.a2@coef["b2"]*log.area) %>% # yhat for reg line
select(lang.hat, log.area, lb.mu, ub.mu, lb.lang, ub.lang)
a <- data %>%
ggplot(aes(data$mean.growing.season)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Meaning Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
predictions <-
as.tibble(MASS::mvrnorm(mu = model.b2@coef, Sigma = model.b2@vcov , n = 1e4)) %>% #rather than extract.samples
mutate(sd.growing.season = sample(data$sd.growing.season, 1e4, replace = T),
log.area = sample(data$log.area, 1e4, replace = T),
pred.mu = a + b2*sd.growing.season + b2*log.area, #line uncertainty
pred.lang= rnorm(1e4, pred.mu, sigma )) %>%         #data uncertainty
group_by(log.area) %>%
mutate(lb.mu = rethinking::HPDI(pred.mu, prob = .89)[1],
ub.mu = rethinking::HPDI(pred.mu, prob = .89)[2],
lb.lang = rethinking::HPDI(pred.lang, prob = .89)[1],
ub.lang = rethinking::HPDI(pred.lang, prob = .89)[2]) %>%
slice(1) %>%
mutate(lang.hat = model.b2@coef["a"] + model.b2@coef["b1"]*sd.growing.season + model.b2@coef["b2"]*log.area) %>% # yhat for reg line
select(lang.hat, log.area, lb.mu, ub.mu, lb.lang, ub.lang)
model.b1 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*sd.growing.season + b2*log.area,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
model.b2 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*sgs.center + b2*log.area,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
compare(model.b1, model.b2) #model.b2
precis(model.b2, digits = 3)
predictions <-
as.tibble(MASS::mvrnorm(mu = model.b2@coef, Sigma = model.b2@vcov , n = 1e4)) %>% #rather than extract.samples
mutate(sd.growing.season = sample(data$sd.growing.season, 1e4, replace = T),
log.area = sample(data$log.area, 1e4, replace = T),
pred.mu = a + b2*sd.growing.season + b2*log.area, #line uncertainty
pred.lang= rnorm(1e4, pred.mu, sigma )) %>%         #data uncertainty
group_by(log.area) %>%
mutate(lb.mu = rethinking::HPDI(pred.mu, prob = .89)[1],
ub.mu = rethinking::HPDI(pred.mu, prob = .89)[2],
lb.lang = rethinking::HPDI(pred.lang, prob = .89)[1],
ub.lang = rethinking::HPDI(pred.lang, prob = .89)[2]) %>%
slice(1) %>%
mutate(lang.hat = model.b2@coef["a"] + model.b2@coef["b1"]*sd.growing.season + model.b2@coef["b2"]*log.area) %>% # yhat for reg line
select(lang.hat, log.area, lb.mu, ub.mu, lb.lang, ub.lang)
a <- data %>%
ggplot(aes(sd.growing.season)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Standard Deviation Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
predictions <-
as.tibble(MASS::mvrnorm(mu = model.b2@coef, Sigma = model.b2@vcov , n = 1e4)) %>% #rather than extract.samples
mutate(sd.growing.season = sample(data$sd.growing.season, 1e4, replace = T),
log.area = sample(data$log.area, 1e4, replace = T),
pred.mu = a + b2*sd.growing.season + b2*log.area, #line uncertainty
pred.lang= rnorm(1e4, pred.mu, sigma )) %>%         #data uncertainty
group_by(log.area) %>%
mutate(lb.mu = rethinking::HPDI(pred.mu, prob = .89)[1],
ub.mu = rethinking::HPDI(pred.mu, prob = .89)[2],
lb.lang = rethinking::HPDI(pred.lang, prob = .89)[1],
ub.lang = rethinking::HPDI(pred.lang, prob = .89)[2]) %>%
slice(1) %>%
mutate(lang.hat = model.b2@coef["a"] + model.b2@coef["b1"]*sd.growing.season + model.b2@coef["b2"]*log.area) %>% # yhat for reg line
select(lang.hat, log.area, lb.mu, ub.mu, lb.lang, ub.lang)
a <- data %>%
ggplot(aes(data$sd.growing.season)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Standard Deviation Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
model.c1 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*log.area + b2*mgs.center + b3*sgs.center + b4*mgs.center*sgs.center,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
b3 ~ dnorm(0, 10),
b4 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
model.c2 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*log.area + b2*mean.growing.season + b3*sd.growing.season + b4*mean.growing.season*sd.growing.season,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
b3 ~ dnorm(0, 10),
b4 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
model.c3 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*log.area + b2*mean.growing.season + b3*sgs.center + b4*mean.growing.season*sgs.center,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
b3 ~ dnorm(0, 10),
b4 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
model.c4 <- map(alist(
log.lang.per.cap ~ dnorm(mu, sigma),
mu <- a + b1*log.area + b2*mgs.center + b3*sd.growing.season + b4*mgs.center*sd.growing.season,
a ~ dnorm(0, 50),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
b3 ~ dnorm(0, 10),
b4 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data)
compare(model.c1, model.c2, model.c3, model.c4) #model.c3 not any more complex than the others but has the highest probability of making correct predictions
precis(model.c3, digits = 3)
predictions <-
as.tibble(MASS::mvrnorm(mu = model.c3@coef, Sigma = model.c3@vcov , n = 1e4)) %>% #rather than extract.samples
mutate(mean.growing.season = sample(data$mean.growing.season, 1e4, replace = T),
log.area = sample(data$log.area, 1e4, replace = T),
sgs.center = sample(data$sgs.center, 1e4, replace = T),
pred.mu = a + b1*log.area + b2*mean.growing.season + b3*sgs.center + b4*mean.growing.season*sgs.center, #line uncertainty
pred.lang= rnorm(1e4, pred.mu, sigma )) %>%         #data uncertainty
group_by(log.area) %>%
mutate(lb.mu = rethinking::HPDI(pred.mu, prob = .89)[1],
ub.mu = rethinking::HPDI(pred.mu, prob = .89)[2],
lb.lang = rethinking::HPDI(pred.lang, prob = .89)[1],
ub.lang = rethinking::HPDI(pred.lang, prob = .89)[2]) %>%
slice(1) %>%
mutate(lang.hat = model.c3@coef["a"] + model.c3@coef["b1"]*log.area + model.c3@coef["b2"]*mean.growing.season + model.c3@coef["b3"]*sgs.center + model.c3@coef["b4"]*mean.growing.season*sgs.center) %>% # yhat for reg line
select(lang.hat, log.area, lb.mu, ub.mu, lb.lang, ub.lang)
a <- data %>%
ggplot(aes(sgs.center)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Centered Standard Deviation Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
a <- data %>%
ggplot(aes(data$sgs.center)) + #makes the x axis growing season for every geom below
geom_jitter(aes(y = log.lang.per.cap)) + #gives a scatter plot of the real data
geom_smooth(data = predictions, aes(y = lang.hat), se= F) + #line ploting predicted heights over real weights
geom_ribbon(data = predictions, aes(ymin = lb.mu, ymax = ub.mu), alpha = .3) + #line uncertainty - tightly fit around line
geom_ribbon(data = predictions, aes(ymin = lb.lang, ymax = ub.lang), color = "green3", alpha = .2) #uncertainty about the data
a + labs(x = "Centered Standard Deviation Growing Season", y = "Log Language Per Capita", title = "Association between Language and Growing Season")
data.ns <- data %>%
filter(country != "Seychelles")
predict_mu <- function(model, predictions){
mu <- link(model, data=predictions)
mu.mean <- apply(mu, 2, mean)
mu.pi <- apply(mu, 2, PI)
list(mean=mu.mean, pi=mu.pi)}
plot_model_mu <- function(raw.data, predictions, pred.mu, title){
plot(log.gdp ~ rugged, data=d.raw, col='blue', ylim=c(5,12), xlim=c(-2, 6))
lines(predictions$rugged, pred.mu$mean, col='red')
shade(pred.mu$pi, predictions$rugged)
mtext(title)}
model1 <- map(alist(
log.gdp ~ dnorm (mu, sigma),
mu <- a + b1*rugged,
a ~ dnorm(8, 100),
b1 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data.ns, method="Nelder-Mead", control=list(maxit=1e4))
data.ns <- data %>%
filter(country != "Seychelles")
model1 <- map(alist(
log.gdp ~ dnorm (mu, sigma),
mu <- a + b1*rugged,
a ~ dnorm(8, 100),
b1 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data.ns, method="Nelder-Mead", control=list(maxit=1e4))
View(data)
data(rugged)
data <- rugged
data <- data %>%
filter(complete.cases(rgdppc_2000))
data <- data %>%
mutate(log.gdp = log(rgdppc_2000))
data.ns <- data %>%
filter(country != "Seychelles")
model1 <- map(alist(
log.gdp ~ dnorm (mu, sigma),
mu <- a + b1*rugged,
a ~ dnorm(8, 100),
b1 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data.ns, method="Nelder-Mead", control=list(maxit=1e4))
model2 <- map(alist(
log.gdp ~ dnorm (mu, sigma),
mu <- a + b1*rugged + b2*cont_africa,
a ~ dnorm(8, 100),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data.ns, method="Nelder-Mead", control=list(maxit=1e4))
model3 <- map(alist(
log.gdp ~ dnorm (mu, sigma),
mu <- a + b1*rugged + b2*cont_africa + b3*rugged*cont_africa,
a ~ dnorm(8, 100),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
b3 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data, method="Nelder-Mead", control=list(maxit=1e4))
model3 <- map(alist(
log.gdp ~ dnorm (mu, sigma),
mu <- a + b1*rugged + b2*cont_africa + b3*rugged*cont_africa,
a ~ dnorm(8, 100),
b1 ~ dnorm(0, 10),
b2 ~ dnorm(0, 10),
b3 ~ dnorm(0, 10),
sigma ~ dunif(0, 10)), data = data, method="Nelder-Mead", control=list(maxit=1e4))
